#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
import pandas as pd


# In[2]:


df = pd.read_csv('spam.csv', encoding='latin1')


# In[3]:


df.sample(5)


# In[4]:


df.shape


# In[5]:


df.info()


# In[6]:


df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)


# In[7]:


df.sample(5)


# In[8]:


df.rename(columns={'v1':'target','v2':'text'},inplace=True)
df.sample(5)


# In[9]:


from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()


# In[10]:


df['target'] = encoder.fit_transform(df['target'])


# In[11]:


df.head()


# In[12]:


df.isnull().sum()


# In[13]:


df.duplicated().sum()


# In[14]:


df = df.drop_duplicates(keep='first')


# In[15]:


df.duplicated().sum()


# In[16]:


df.shape


# In[17]:


df.head()


# In[21]:


df['target'].value_counts()


# In[19]:


pip install matplotlib


# In[20]:


import matplotlib.pyplot as plt
plt.pie(df['target'].value_counts(), labels=['ham','spam'],autopct="%0.2f")
plt.show()


# In[22]:


import nltk


# In[23]:


nltk.download('punkt')


# In[24]:


df['num_characters'] = df['text'].apply(len)


# In[25]:


df.head()


# In[26]:


df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))
df.head()


# In[27]:


df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))


# In[28]:


df.head()


# In[29]:


df[['num_characters','num_words','num_sentences']].describe()


# In[30]:


df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()


# In[ ]:




